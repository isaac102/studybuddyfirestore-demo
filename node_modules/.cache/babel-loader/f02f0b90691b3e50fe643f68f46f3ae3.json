{"ast":null,"code":"/**\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { assert } from '../util/assert';\nimport { encode } from './encoded_resource_path';\nimport { PersistencePromise } from './persistence_promise';\nimport { SnapshotVersion } from '../core/snapshot_version';\n/**\n * Schema Version for the Web client:\n * 1. Initial version including Mutation Queue, Query Cache, and Remote Document\n *    Cache\n * 2. Added targetCount to targetGlobal row.\n */\n\nexport var SCHEMA_VERSION = 2;\n/**\n * Performs database creation and schema upgrades.\n *\n * Note that in production, this method is only ever used to upgrade the schema\n * to SCHEMA_VERSION. Different values of toVersion are only used for testing\n * and local feature development.\n */\n\nexport function createOrUpgradeDb(db, txn, fromVersion, toVersion) {\n  // This function currently supports migrating to schema version 1 (Mutation\n  // Queue, Query and Remote Document Cache) and schema version 2 (Query\n  // counting).\n  assert(fromVersion < toVersion && fromVersion >= 0 && toVersion <= 2, 'Unexpected schema upgrade from v${fromVersion} to v{toVersion}.');\n\n  if (fromVersion < 1 && toVersion >= 1) {\n    createOwnerStore(db);\n    createMutationQueue(db);\n    createQueryCache(db);\n    createRemoteDocumentCache(db);\n  }\n\n  var p = PersistencePromise.resolve();\n\n  if (fromVersion < 2 && toVersion >= 2) {\n    p = ensureTargetGlobalExists(txn).next(function (targetGlobal) {\n      return saveTargetCount(txn, targetGlobal);\n    });\n  }\n\n  return p;\n}\n/**\n * Wrapper class to store timestamps (seconds and nanos) in IndexedDb objects.\n */\n\nvar DbTimestamp =\n/** @class */\nfunction () {\n  function DbTimestamp(seconds, nanos) {\n    this.seconds = seconds;\n    this.nanos = nanos;\n  }\n\n  return DbTimestamp;\n}();\n\nexport { DbTimestamp };\n/**\n * A singleton object to be stored in the 'owner' store in IndexedDb.\n *\n * A given database can be owned by a single tab at a given time. That tab\n * must validate that it is still the owner before every write operation and\n * should regularly write an updated timestamp to prevent other tabs from\n * \"stealing\" ownership of the db.\n */\n\nvar DbOwner =\n/** @class */\nfunction () {\n  function DbOwner(ownerId, leaseTimestampMs) {\n    this.ownerId = ownerId;\n    this.leaseTimestampMs = leaseTimestampMs;\n  }\n  /** Name of the IndexedDb object store. */\n\n\n  DbOwner.store = 'owner';\n  return DbOwner;\n}();\n\nexport { DbOwner };\n\nfunction createOwnerStore(db) {\n  db.createObjectStore(DbOwner.store);\n}\n/**\n * An object to be stored in the 'mutationQueues' store in IndexedDb.\n *\n * Each user gets a single queue of MutationBatches to apply to the server.\n * DbMutationQueue tracks the metadata about the queue.\n */\n\n\nvar DbMutationQueue =\n/** @class */\nfunction () {\n  function DbMutationQueue(\n  /**\n   * The normalized user ID to which this queue belongs.\n   */\n  userId,\n  /**\n   * An identifier for the highest numbered batch that has been acknowledged\n   * by the server. All MutationBatches in this queue with batchIds less\n   * than or equal to this value are considered to have been acknowledged by\n   * the server.\n   */\n  lastAcknowledgedBatchId,\n  /**\n   * A stream token that was previously sent by the server.\n   *\n   * See StreamingWriteRequest in datastore.proto for more details about\n   * usage.\n   *\n   * After sending this token, earlier tokens may not be used anymore so\n   * only a single stream token is retained.\n   */\n  lastStreamToken) {\n    this.userId = userId;\n    this.lastAcknowledgedBatchId = lastAcknowledgedBatchId;\n    this.lastStreamToken = lastStreamToken;\n  }\n  /** Name of the IndexedDb object store.  */\n\n\n  DbMutationQueue.store = 'mutationQueues';\n  /** Keys are automatically assigned via the userId property. */\n\n  DbMutationQueue.keyPath = 'userId';\n  return DbMutationQueue;\n}();\n\nexport { DbMutationQueue };\n/**\n * An object to be stored in the 'mutations' store in IndexedDb.\n *\n * Represents a batch of user-level mutations intended to be sent to the server\n * in a single write. Each user-level batch gets a separate DbMutationBatch\n * with a new batchId.\n */\n\nvar DbMutationBatch =\n/** @class */\nfunction () {\n  function DbMutationBatch(\n  /**\n   * The normalized user ID to which this batch belongs.\n   */\n  userId,\n  /**\n   * An identifier for this batch, allocated by the mutation queue in a\n   * monotonically increasing manner.\n   */\n  batchId,\n  /**\n   * The local write time of the batch, stored as milliseconds since the\n   * epoch.\n   */\n  localWriteTimeMs,\n  /**\n   * A list of mutations to apply. All mutations will be applied atomically.\n   *\n   * Mutations are serialized via JsonProtoSerializer.toMutation().\n   */\n  mutations) {\n    this.userId = userId;\n    this.batchId = batchId;\n    this.localWriteTimeMs = localWriteTimeMs;\n    this.mutations = mutations;\n  }\n  /** Name of the IndexedDb object store.  */\n\n\n  DbMutationBatch.store = 'mutations';\n  /** Keys are automatically assigned via the userId, batchId properties. */\n\n  DbMutationBatch.keyPath = ['userId', 'batchId'];\n  return DbMutationBatch;\n}();\n\nexport { DbMutationBatch };\n\nfunction createMutationQueue(db) {\n  db.createObjectStore(DbMutationQueue.store, {\n    keyPath: DbMutationQueue.keyPath\n  });\n  db.createObjectStore(DbMutationBatch.store, {\n    keyPath: DbMutationBatch.keyPath\n  });\n  db.createObjectStore(DbDocumentMutation.store);\n}\n/**\n * An object to be stored in the 'documentMutations' store in IndexedDb.\n *\n * A manually maintained index of all the mutation batches that affect a given\n * document key. The rows in this table are references based on the contents of\n * DbMutationBatch.mutations.\n */\n\n\nvar DbDocumentMutation =\n/** @class */\nfunction () {\n  function DbDocumentMutation() {}\n  /**\n   * Creates a [userId] key for use in the DbDocumentMutations index to iterate\n   * over all of a user's document mutations.\n   */\n\n\n  DbDocumentMutation.prefixForUser = function (userId) {\n    return [userId];\n  };\n  /**\n   * Creates a [userId, encodedPath] key for use in the DbDocumentMutations\n   * index to iterate over all at document mutations for a given path or lower.\n   */\n\n\n  DbDocumentMutation.prefixForPath = function (userId, path) {\n    return [userId, encode(path)];\n  };\n  /**\n   * Creates a full index key of [userId, encodedPath, batchId] for inserting\n   * and deleting into the DbDocumentMutations index.\n   */\n\n\n  DbDocumentMutation.key = function (userId, path, batchId) {\n    return [userId, encode(path), batchId];\n  };\n\n  DbDocumentMutation.store = 'documentMutations';\n  /**\n   * Because we store all the useful information for this store in the key,\n   * there is no useful information to store as the value. The raw (unencoded)\n   * path cannot be stored because IndexedDb doesn't store prototype\n   * information.\n   */\n\n  DbDocumentMutation.PLACEHOLDER = new DbDocumentMutation();\n  return DbDocumentMutation;\n}();\n\nexport { DbDocumentMutation };\n\nfunction createRemoteDocumentCache(db) {\n  db.createObjectStore(DbRemoteDocument.store);\n}\n/**\n * Represents the known absence of a document at a particular version.\n * Stored in IndexedDb as part of a DbRemoteDocument object.\n */\n\n\nvar DbNoDocument =\n/** @class */\nfunction () {\n  function DbNoDocument(path, readTime) {\n    this.path = path;\n    this.readTime = readTime;\n  }\n\n  return DbNoDocument;\n}();\n\nexport { DbNoDocument };\n/**\n * An object to be stored in the 'remoteDocuments' store in IndexedDb. It\n * represents either a cached document (if it exists) or a cached \"no-document\"\n * (if it is known to not exist).\n *\n * Note: This is the persisted equivalent of a MaybeDocument and could perhaps\n * be made more general if necessary.\n */\n\nvar DbRemoteDocument =\n/** @class */\nfunction () {\n  function DbRemoteDocument(\n  /**\n   * Set to an instance of a DbNoDocument if it is known that no document\n   * exists.\n   */\n  noDocument,\n  /**\n   * Set to an instance of a Document if there's a cached version of the\n   * document.\n   */\n  document) {\n    this.noDocument = noDocument;\n    this.document = document;\n  }\n\n  DbRemoteDocument.store = 'remoteDocuments';\n  return DbRemoteDocument;\n}();\n\nexport { DbRemoteDocument };\n/**\n * An object to be stored in the 'targets' store in IndexedDb.\n *\n * This is based on and should be kept in sync with the proto used in the iOS\n * client.\n *\n * Each query the client listens to against the server is tracked on disk so\n * that the query can be efficiently resumed on restart.\n */\n\nvar DbTarget =\n/** @class */\nfunction () {\n  function DbTarget(\n  /**\n   * An auto-generated sequential numeric identifier for the query.\n   *\n   * Queries are stored using their canonicalId as the key, but these\n   * canonicalIds can be quite long so we additionally assign a unique\n   * queryId which can be used by referenced data structures (e.g.\n   * indexes) to minimize the on-disk cost.\n   */\n  targetId,\n  /**\n   * The canonical string representing this query. This is not unique.\n   */\n  canonicalId,\n  /**\n   * The last readTime received from the Watch Service for this query.\n   *\n   * This is the same value as TargetChange.read_time in the protos.\n   */\n  readTime,\n  /**\n   * An opaque, server-assigned token that allows watching a query to be\n   * resumed after disconnecting without retransmitting all the data\n   * that matches the query. The resume token essentially identifies a\n   * point in time from which the server should resume sending results.\n   *\n   * This is related to the snapshotVersion in that the resumeToken\n   * effectively also encodes that value, but the resumeToken is opaque\n   * and sometimes encodes additional information.\n   *\n   * A consequence of this is that the resumeToken should be used when\n   * asking the server to reason about where this client is in the watch\n   * stream, but the client should use the snapshotVersion for its own\n   * purposes.\n   *\n   * This is the same value as TargetChange.resume_token in the protos.\n   */\n  resumeToken,\n  /**\n   * A sequence number representing the last time this query was\n   * listened to, used for garbage collection purposes.\n   *\n   * Conventionally this would be a timestamp value, but device-local\n   * clocks are unreliable and they must be able to create new listens\n   * even while disconnected. Instead this should be a monotonically\n   * increasing number that's incremented on each listen call.\n   *\n   * This is different from the queryId since the queryId is an\n   * immutable identifier assigned to the Query on first use while\n   * lastListenSequenceNumber is updated every time the query is\n   * listened to.\n   */\n  lastListenSequenceNumber,\n  /**\n   * The query for this target.\n   *\n   * Because canonical ids are not unique we must store the actual query. We\n   * use the proto to have an object we can persist without having to\n   * duplicate translation logic to and from a `Query` object.\n   */\n  query) {\n    this.targetId = targetId;\n    this.canonicalId = canonicalId;\n    this.readTime = readTime;\n    this.resumeToken = resumeToken;\n    this.lastListenSequenceNumber = lastListenSequenceNumber;\n    this.query = query;\n  }\n\n  DbTarget.store = 'targets';\n  /** Keys are automatically assigned via the targetId property. */\n\n  DbTarget.keyPath = 'targetId';\n  /** The name of the queryTargets index. */\n\n  DbTarget.queryTargetsIndexName = 'queryTargetsIndex';\n  /**\n   * The index of all canonicalIds to the targets that they match. This is not\n   * a unique mapping because canonicalId does not promise a unique name for all\n   * possible queries, so we append the targetId to make the mapping unique.\n   */\n\n  DbTarget.queryTargetsKeyPath = ['canonicalId', 'targetId'];\n  return DbTarget;\n}();\n\nexport { DbTarget };\n/**\n * An object representing an association between a target and a document.\n * Stored in the targetDocument object store to store the documents tracked by a\n * particular target.\n */\n\nvar DbTargetDocument =\n/** @class */\nfunction () {\n  function DbTargetDocument(\n  /**\n   * The targetId identifying a target.\n   */\n  targetId,\n  /**\n   * The path to the document, as encoded in the key.\n   */\n  path) {\n    this.targetId = targetId;\n    this.path = path;\n  }\n  /** Name of the IndexedDb object store.  */\n\n\n  DbTargetDocument.store = 'targetDocuments';\n  /** Keys are automatically assigned via the targetId, path properties. */\n\n  DbTargetDocument.keyPath = ['targetId', 'path'];\n  /** The index name for the reverse index. */\n\n  DbTargetDocument.documentTargetsIndex = 'documentTargetsIndex';\n  /** We also need to create the reverse index for these properties. */\n\n  DbTargetDocument.documentTargetsKeyPath = ['path', 'targetId'];\n  return DbTargetDocument;\n}();\n\nexport { DbTargetDocument };\n/**\n * A record of global state tracked across all Targets, tracked separately\n * to avoid the need for extra indexes.\n *\n * This should be kept in-sync with the proto used in the iOS client.\n */\n\nvar DbTargetGlobal =\n/** @class */\nfunction () {\n  function DbTargetGlobal(\n  /**\n   * The highest numbered target id across all targets.\n   *\n   * See DbTarget.targetId.\n   */\n  highestTargetId,\n  /**\n   * The highest numbered lastListenSequenceNumber across all targets.\n   *\n   * See DbTarget.lastListenSequenceNumber.\n   */\n  highestListenSequenceNumber,\n  /**\n   * A global snapshot version representing the last consistent snapshot we\n   * received from the backend. This is monotonically increasing and any\n   * snapshots received from the backend prior to this version (e.g. for\n   * targets resumed with a resumeToken) should be suppressed (buffered)\n   * until the backend has caught up to this snapshot version again. This\n   * prevents our cache from ever going backwards in time.\n   */\n  lastRemoteSnapshotVersion,\n  /**\n   * The number of targets persisted.\n   */\n  targetCount) {\n    this.highestTargetId = highestTargetId;\n    this.highestListenSequenceNumber = highestListenSequenceNumber;\n    this.lastRemoteSnapshotVersion = lastRemoteSnapshotVersion;\n    this.targetCount = targetCount;\n  }\n  /**\n   * The key string used for the single object that exists in the\n   * DbTargetGlobal store.\n   */\n\n\n  DbTargetGlobal.key = 'targetGlobalKey';\n  DbTargetGlobal.store = 'targetGlobal';\n  return DbTargetGlobal;\n}();\n\nexport { DbTargetGlobal };\n\nfunction createQueryCache(db) {\n  var targetDocumentsStore = db.createObjectStore(DbTargetDocument.store, {\n    keyPath: DbTargetDocument.keyPath\n  });\n  targetDocumentsStore.createIndex(DbTargetDocument.documentTargetsIndex, DbTargetDocument.documentTargetsKeyPath, {\n    unique: true\n  });\n  var targetStore = db.createObjectStore(DbTarget.store, {\n    keyPath: DbTarget.keyPath\n  }); // NOTE: This is unique only because the TargetId is the suffix.\n\n  targetStore.createIndex(DbTarget.queryTargetsIndexName, DbTarget.queryTargetsKeyPath, {\n    unique: true\n  });\n  db.createObjectStore(DbTargetGlobal.store);\n}\n/**\n * Counts the number of targets persisted and adds that value to the target\n * global singleton.\n */\n\n\nfunction saveTargetCount(txn, metadata) {\n  var globalStore = txn.store(DbTargetGlobal.store);\n  var targetStore = txn.store(DbTarget.store);\n  return targetStore.count().next(function (count) {\n    metadata.targetCount = count;\n    return globalStore.put(DbTargetGlobal.key, metadata);\n  });\n}\n/**\n * Ensures that the target global singleton row exists by adding it if it's\n * missing.\n *\n * @param {IDBTransaction} txn The version upgrade transaction for indexeddb\n */\n\n\nfunction ensureTargetGlobalExists(txn) {\n  var globalStore = txn.store(DbTargetGlobal.store);\n  return globalStore.get(DbTargetGlobal.key).next(function (metadata) {\n    if (metadata != null) {\n      return PersistencePromise.resolve(metadata);\n    } else {\n      metadata = new DbTargetGlobal(\n      /*highestTargetId=*/\n      0,\n      /*lastListenSequenceNumber=*/\n      0, SnapshotVersion.MIN.toTimestamp(),\n      /*targetCount=*/\n      0);\n      return globalStore.put(DbTargetGlobal.key, metadata).next(function () {\n        return metadata;\n      });\n    }\n  });\n}\n/**\n * The list of all default IndexedDB stores used throughout the SDK. This is\n * used when creating transactions so that access across all stores is done\n * atomically.\n */\n\n\nexport var ALL_STORES = [DbMutationQueue.store, DbMutationBatch.store, DbDocumentMutation.store, DbRemoteDocument.store, DbTarget.store, DbOwner.store, DbTargetGlobal.store, DbTargetDocument.store];","map":{"version":3,"sources":["../src/local/indexeddb_schema.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;AAcG;AAMH,SAAS,MAAT,QAAuB,gBAAvB;AAEA,SAAS,MAAT,QAA4C,yBAA5C;AAEA,SAAS,kBAAT,QAAmC,uBAAnC;AACA,SAAS,eAAT,QAAgC,0BAAhC;AAEA;;;;;AAKG;;AACH,OAAO,IAAM,cAAc,GAAG,CAAvB;AAEP;;;;;;AAMG;;AACH,OAAM,SAAA,iBAAA,CACJ,EADI,EAEJ,GAFI,EAGJ,WAHI,EAIJ,SAJI,EAIa;AAEjB;AACA;AACA;AACA,EAAA,MAAM,CACJ,WAAW,GAAG,SAAd,IAA2B,WAAW,IAAI,CAA1C,IAA+C,SAAS,IAAI,CADxD,EAEJ,iEAFI,CAAN;;AAKA,MAAI,WAAW,GAAG,CAAd,IAAmB,SAAS,IAAI,CAApC,EAAuC;AACrC,IAAA,gBAAgB,CAAC,EAAD,CAAhB;AACA,IAAA,mBAAmB,CAAC,EAAD,CAAnB;AACA,IAAA,gBAAgB,CAAC,EAAD,CAAhB;AACA,IAAA,yBAAyB,CAAC,EAAD,CAAzB;AACD;;AAED,MAAI,CAAC,GAAG,kBAAkB,CAAC,OAAnB,EAAR;;AACA,MAAI,WAAW,GAAG,CAAd,IAAmB,SAAS,IAAI,CAApC,EAAuC;AACrC,IAAA,CAAC,GAAG,wBAAwB,CAAC,GAAD,CAAxB,CAA8B,IAA9B,CAAmC,UAAA,YAAA,EAAY;AACjD,aAAA,eAAe,CAAC,GAAD,EAAM,YAAN,CAAf;AAAkC,KADhC,CAAJ;AAGD;;AACD,SAAO,CAAP;AACD;AAMD;;AAEG;;AACH,IAAA,WAAA;AAAA;AAAA,YAAA;AACE,WAAA,WAAA,CAAmB,OAAnB,EAA2C,KAA3C,EAAwD;AAArC,SAAA,OAAA,GAAA,OAAA;AAAwB,SAAA,KAAA,GAAA,KAAA;AAAiB;;AAC9D,SAAA,WAAA;AAAC,CAFD,EAAA;;;AAOA;;;;;;;AAOG;;AACH,IAAA,OAAA;AAAA;AAAA,YAAA;AAIE,WAAA,OAAA,CAAmB,OAAnB,EAA2C,gBAA3C,EAAmE;AAAhD,SAAA,OAAA,GAAA,OAAA;AAAwB,SAAA,gBAAA,GAAA,gBAAA;AAA4B;AAHvE;;;AACO,EAAA,OAAA,CAAA,KAAA,GAAQ,OAAR;AAGT,SAAA,OAAA;AAAC,CALD,EAAA;;SAAa,O;;AAOb,SAAA,gBAAA,CAA0B,EAA1B,EAAyC;AACvC,EAAA,EAAE,CAAC,iBAAH,CAAqB,OAAO,CAAC,KAA7B;AACD;AAKD;;;;;AAKG;;;AACH,IAAA,eAAA;AAAA;AAAA,YAAA;AAOE,WAAA,eAAA;AACE;;AAEG;AACI,EAAA,MAJT;AAKE;;;;;AAKG;AACI,EAAA,uBAXT;AAYE;;;;;;;;AAQG;AACI,EAAA,eArBT,EAqBgC;AAjBvB,SAAA,MAAA,GAAA,MAAA;AAOA,SAAA,uBAAA,GAAA,uBAAA;AAUA,SAAA,eAAA,GAAA,eAAA;AACL;AA5BJ;;;AACO,EAAA,eAAA,CAAA,KAAA,GAAQ,gBAAR;AAEP;;AACO,EAAA,eAAA,CAAA,OAAA,GAAU,QAAV;AAyBT,SAAA,eAAA;AAAC,CA9BD,EAAA;;SAAa,e;AAmCb;;;;;;AAMG;;AACH,IAAA,eAAA;AAAA;AAAA,YAAA;AAOE,WAAA,eAAA;AACE;;AAEG;AACI,EAAA,MAJT;AAKE;;;AAGG;AACI,EAAA,OATT;AAUE;;;AAGG;AACI,EAAA,gBAdT;AAeE;;;;AAIG;AACI,EAAA,SApBT,EAoB+B;AAhBtB,SAAA,MAAA,GAAA,MAAA;AAKA,SAAA,OAAA,GAAA,OAAA;AAKA,SAAA,gBAAA,GAAA,gBAAA;AAMA,SAAA,SAAA,GAAA,SAAA;AACL;AA3BJ;;;AACO,EAAA,eAAA,CAAA,KAAA,GAAQ,WAAR;AAEP;;AACO,EAAA,eAAA,CAAA,OAAA,GAAU,CAAC,QAAD,EAAW,SAAX,CAAV;AAwBT,SAAA,eAAA;AAAC,CA7BD,EAAA;;SAAa,e;;AAsCb,SAAA,mBAAA,CAA6B,EAA7B,EAA4C;AAC1C,EAAA,EAAE,CAAC,iBAAH,CAAqB,eAAe,CAAC,KAArC,EAA4C;AAC1C,IAAA,OAAO,EAAE,eAAe,CAAC;AADiB,GAA5C;AAIA,EAAA,EAAE,CAAC,iBAAH,CAAqB,eAAe,CAAC,KAArC,EAA4C;AAC1C,IAAA,OAAO,EAAE,eAAe,CAAC;AADiB,GAA5C;AAIA,EAAA,EAAE,CAAC,iBAAH,CAAqB,kBAAkB,CAAC,KAAxC;AACD;AAED;;;;;;AAMG;;;AACH,IAAA,kBAAA;AAAA;AAAA,YAAA;AA0CE,WAAA,kBAAA,GAAA,CAAwB;AAvCxB;;;AAGG;;;AACI,EAAA,kBAAA,CAAA,aAAA,GAAP,UAAqB,MAArB,EAAmC;AACjC,WAAO,CAAC,MAAD,CAAP;AACD,GAFM;AAIP;;;AAGG;;;AACI,EAAA,kBAAA,CAAA,aAAA,GAAP,UACE,MADF,EAEE,IAFF,EAEoB;AAElB,WAAO,CAAC,MAAD,EAAS,MAAM,CAAC,IAAD,CAAf,CAAP;AACD,GALM;AAOP;;;AAGG;;;AACI,EAAA,kBAAA,CAAA,GAAA,GAAP,UACE,MADF,EAEE,IAFF,EAGE,OAHF,EAGkB;AAEhB,WAAO,CAAC,MAAD,EAAS,MAAM,CAAC,IAAD,CAAf,EAAuB,OAAvB,CAAP;AACD,GANM;;AAzBA,EAAA,kBAAA,CAAA,KAAA,GAAQ,mBAAR;AAiCP;;;;;AAKG;;AACI,EAAA,kBAAA,CAAA,WAAA,GAAc,IAAI,kBAAJ,EAAd;AAGT,SAAA,kBAAA;AAAC,CA3CD,EAAA;;SAAa,kB;;AAmDb,SAAA,yBAAA,CAAmC,EAAnC,EAAkD;AAChD,EAAA,EAAE,CAAC,iBAAH,CAAqB,gBAAgB,CAAC,KAAtC;AACD;AAED;;;AAGG;;;AACH,IAAA,YAAA;AAAA;AAAA,YAAA;AACE,WAAA,YAAA,CAAmB,IAAnB,EAA0C,QAA1C,EAA+D;AAA5C,SAAA,IAAA,GAAA,IAAA;AAAuB,SAAA,QAAA,GAAA,QAAA;AAAyB;;AACrE,SAAA,YAAA;AAAC,CAFD,EAAA;;;AAIA;;;;;;;AAOG;;AACH,IAAA,gBAAA;AAAA;AAAA,YAAA;AAGE,WAAA,gBAAA;AACE;;;AAGG;AACI,EAAA,UALT;AAME;;;AAGG;AACI,EAAA,QAVT,EAUsC;AAL7B,SAAA,UAAA,GAAA,UAAA;AAKA,SAAA,QAAA,GAAA,QAAA;AACL;;AAbG,EAAA,gBAAA,CAAA,KAAA,GAAQ,iBAAR;AAcT,SAAA,gBAAA;AAAC,CAfD,EAAA;;SAAa,gB;AA6Bb;;;;;;;;AAQG;;AACH,IAAA,QAAA;AAAA;AAAA,YAAA;AAgBE,WAAA,QAAA;AACE;;;;;;;AAOG;AACI,EAAA,QATT;AAUE;;AAEG;AACI,EAAA,WAbT;AAcE;;;;AAIG;AACI,EAAA,QAnBT;AAoBE;;;;;;;;;;;;;;;;AAgBG;AACI,EAAA,WArCT;AAsCE;;;;;;;;;;;;;AAaG;AACI,EAAA,wBApDT;AAqDE;;;;;;AAMG;AACI,EAAA,KA5DT,EA4DuB;AAnDd,SAAA,QAAA,GAAA,QAAA;AAIA,SAAA,WAAA,GAAA,WAAA;AAMA,SAAA,QAAA,GAAA,QAAA;AAkBA,SAAA,WAAA,GAAA,WAAA;AAeA,SAAA,wBAAA,GAAA,wBAAA;AAQA,SAAA,KAAA,GAAA,KAAA;AACL;;AA5EG,EAAA,QAAA,CAAA,KAAA,GAAQ,SAAR;AAEP;;AACO,EAAA,QAAA,CAAA,OAAA,GAAU,UAAV;AAEP;;AACO,EAAA,QAAA,CAAA,qBAAA,GAAwB,mBAAxB;AAEP;;;;AAIG;;AACI,EAAA,QAAA,CAAA,mBAAA,GAAsB,CAAC,aAAD,EAAgB,UAAhB,CAAtB;AAgET,SAAA,QAAA;AAAC,CA9ED,EAAA;;SAAa,Q;AAsFb;;;;AAIG;;AACH,IAAA,gBAAA;AAAA;AAAA,YAAA;AAaE,WAAA,gBAAA;AACE;;AAEG;AACI,EAAA,QAJT;AAKE;;AAEG;AACI,EAAA,IART,EAQkC;AAJzB,SAAA,QAAA,GAAA,QAAA;AAIA,SAAA,IAAA,GAAA,IAAA;AACL;AArBJ;;;AACO,EAAA,gBAAA,CAAA,KAAA,GAAQ,iBAAR;AAEP;;AACO,EAAA,gBAAA,CAAA,OAAA,GAAU,CAAC,UAAD,EAAa,MAAb,CAAV;AAEP;;AACO,EAAA,gBAAA,CAAA,oBAAA,GAAuB,sBAAvB;AAEP;;AACO,EAAA,gBAAA,CAAA,sBAAA,GAAyB,CAAC,MAAD,EAAS,UAAT,CAAzB;AAYT,SAAA,gBAAA;AAAC,CAvBD,EAAA;;SAAa,gB;AA8Bb;;;;;AAKG;;AACH,IAAA,cAAA;AAAA;AAAA,YAAA;AAQE,WAAA,cAAA;AACE;;;;AAIG;AACI,EAAA,eANT;AAOE;;;;AAIG;AACI,EAAA,2BAZT;AAaE;;;;;;;AAOG;AACI,EAAA,yBArBT;AAsBE;;AAEG;AACI,EAAA,WAzBT,EAyB4B;AAnBnB,SAAA,eAAA,GAAA,eAAA;AAMA,SAAA,2BAAA,GAAA,2BAAA;AASA,SAAA,yBAAA,GAAA,yBAAA;AAIA,SAAA,WAAA,GAAA,WAAA;AACL;AAjCJ;;;AAGG;;;AACI,EAAA,cAAA,CAAA,GAAA,GAAM,iBAAN;AACA,EAAA,cAAA,CAAA,KAAA,GAAQ,cAAR;AA6BT,SAAA,cAAA;AAAC,CAnCD,EAAA;;SAAa,c;;AAqCb,SAAA,gBAAA,CAA0B,EAA1B,EAAyC;AACvC,MAAM,oBAAoB,GAAG,EAAE,CAAC,iBAAH,CAAqB,gBAAgB,CAAC,KAAtC,EAA6C;AACxE,IAAA,OAAO,EAAE,gBAAgB,CAAC;AAD8C,GAA7C,CAA7B;AAGA,EAAA,oBAAoB,CAAC,WAArB,CACE,gBAAgB,CAAC,oBADnB,EAEE,gBAAgB,CAAC,sBAFnB,EAGE;AAAE,IAAA,MAAM,EAAE;AAAV,GAHF;AAMA,MAAM,WAAW,GAAG,EAAE,CAAC,iBAAH,CAAqB,QAAQ,CAAC,KAA9B,EAAqC;AACvD,IAAA,OAAO,EAAE,QAAQ,CAAC;AADqC,GAArC,CAApB,CAVuC,CAcvC;;AACA,EAAA,WAAW,CAAC,WAAZ,CACE,QAAQ,CAAC,qBADX,EAEE,QAAQ,CAAC,mBAFX,EAGE;AAAE,IAAA,MAAM,EAAE;AAAV,GAHF;AAKA,EAAA,EAAE,CAAC,iBAAH,CAAqB,cAAc,CAAC,KAApC;AACD;AAED;;;AAGG;;;AACH,SAAA,eAAA,CACE,GADF,EAEE,QAFF,EAE0B;AAExB,MAAM,WAAW,GAAG,GAAG,CAAC,KAAJ,CAClB,cAAc,CAAC,KADG,CAApB;AAGA,MAAM,WAAW,GAAG,GAAG,CAAC,KAAJ,CAAiC,QAAQ,CAAC,KAA1C,CAApB;AACA,SAAO,WAAW,CAAC,KAAZ,GAAoB,IAApB,CAAyB,UAAA,KAAA,EAAK;AACnC,IAAA,QAAQ,CAAC,WAAT,GAAuB,KAAvB;AACA,WAAO,WAAW,CAAC,GAAZ,CAAgB,cAAc,CAAC,GAA/B,EAAoC,QAApC,CAAP;AACD,GAHM,CAAP;AAID;AAED;;;;;AAKG;;;AACH,SAAA,wBAAA,CACE,GADF,EAC0B;AAExB,MAAM,WAAW,GAAG,GAAG,CAAC,KAAJ,CAClB,cAAc,CAAC,KADG,CAApB;AAGA,SAAO,WAAW,CAAC,GAAZ,CAAgB,cAAc,CAAC,GAA/B,EAAoC,IAApC,CAAyC,UAAA,QAAA,EAAQ;AACtD,QAAI,QAAQ,IAAI,IAAhB,EAAsB;AACpB,aAAO,kBAAkB,CAAC,OAAnB,CAA2B,QAA3B,CAAP;AACD,KAFD,MAEO;AACL,MAAA,QAAQ,GAAG,IAAI,cAAJ;AACT;AAAqB,OADZ;AAET;AAA8B,OAFrB,EAGT,eAAe,CAAC,GAAhB,CAAoB,WAApB,EAHS;AAIT;AAAiB,OAJR,CAAX;AAMA,aAAO,WAAW,CAAC,GAAZ,CAAgB,cAAc,CAAC,GAA/B,EAAoC,QAApC,EAA8C,IAA9C,CAAmD,YAAA;AAAM,eAAA,QAAA;AAAQ,OAAjE,CAAP;AACD;AACF,GAZM,CAAP;AAaD;AAED;;;;AAIG;;;AACH,OAAO,IAAM,UAAU,GAAG,CACxB,eAAe,CAAC,KADQ,EAExB,eAAe,CAAC,KAFQ,EAGxB,kBAAkB,CAAC,KAHK,EAIxB,gBAAgB,CAAC,KAJO,EAKxB,QAAQ,CAAC,KALe,EAMxB,OAAO,CAAC,KANgB,EAOxB,cAAc,CAAC,KAPS,EAQxB,gBAAgB,CAAC,KARO,CAAnB","sourcesContent":["/**\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\nimport { BatchId } from '../core/types';\nimport { TargetId } from '../core/types';\nimport { ResourcePath } from '../model/path';\nimport { assert } from '../util/assert';\n\nimport { encode, EncodedResourcePath } from './encoded_resource_path';\nimport { SimpleDbTransaction } from './simple_db';\nimport { PersistencePromise } from './persistence_promise';\nimport { SnapshotVersion } from '../core/snapshot_version';\n\n/**\n * Schema Version for the Web client:\n * 1. Initial version including Mutation Queue, Query Cache, and Remote Document\n *    Cache\n * 2. Added targetCount to targetGlobal row.\n */\nexport const SCHEMA_VERSION = 2;\n\n/**\n * Performs database creation and schema upgrades.\n *\n * Note that in production, this method is only ever used to upgrade the schema\n * to SCHEMA_VERSION. Different values of toVersion are only used for testing\n * and local feature development.\n */\nexport function createOrUpgradeDb(\n  db: IDBDatabase,\n  txn: SimpleDbTransaction,\n  fromVersion: number,\n  toVersion: number\n): PersistencePromise<void> {\n  // This function currently supports migrating to schema version 1 (Mutation\n  // Queue, Query and Remote Document Cache) and schema version 2 (Query\n  // counting).\n  assert(\n    fromVersion < toVersion && fromVersion >= 0 && toVersion <= 2,\n    'Unexpected schema upgrade from v${fromVersion} to v{toVersion}.'\n  );\n\n  if (fromVersion < 1 && toVersion >= 1) {\n    createOwnerStore(db);\n    createMutationQueue(db);\n    createQueryCache(db);\n    createRemoteDocumentCache(db);\n  }\n\n  let p = PersistencePromise.resolve();\n  if (fromVersion < 2 && toVersion >= 2) {\n    p = ensureTargetGlobalExists(txn).next(targetGlobal =>\n      saveTargetCount(txn, targetGlobal)\n    );\n  }\n  return p;\n}\n\n// TODO(mikelehen): Get rid of \"as any\" if/when TypeScript fixes their types.\n// https://github.com/Microsoft/TypeScript/issues/14322\ntype KeyPath = any; // tslint:disable-line:no-any\n\n/**\n * Wrapper class to store timestamps (seconds and nanos) in IndexedDb objects.\n */\nexport class DbTimestamp {\n  constructor(public seconds: number, public nanos: number) {}\n}\n\n// The key for the singleton object in the 'owner' store is 'owner'.\nexport type DbOwnerKey = 'owner';\n\n/**\n * A singleton object to be stored in the 'owner' store in IndexedDb.\n *\n * A given database can be owned by a single tab at a given time. That tab\n * must validate that it is still the owner before every write operation and\n * should regularly write an updated timestamp to prevent other tabs from\n * \"stealing\" ownership of the db.\n */\nexport class DbOwner {\n  /** Name of the IndexedDb object store. */\n  static store = 'owner';\n\n  constructor(public ownerId: string, public leaseTimestampMs: number) {}\n}\n\nfunction createOwnerStore(db: IDBDatabase): void {\n  db.createObjectStore(DbOwner.store);\n}\n\n/** Object keys in the 'mutationQueues' store are userId strings. */\nexport type DbMutationQueueKey = string;\n\n/**\n * An object to be stored in the 'mutationQueues' store in IndexedDb.\n *\n * Each user gets a single queue of MutationBatches to apply to the server.\n * DbMutationQueue tracks the metadata about the queue.\n */\nexport class DbMutationQueue {\n  /** Name of the IndexedDb object store.  */\n  static store = 'mutationQueues';\n\n  /** Keys are automatically assigned via the userId property. */\n  static keyPath = 'userId';\n\n  constructor(\n    /**\n     * The normalized user ID to which this queue belongs.\n     */\n    public userId: string,\n    /**\n     * An identifier for the highest numbered batch that has been acknowledged\n     * by the server. All MutationBatches in this queue with batchIds less\n     * than or equal to this value are considered to have been acknowledged by\n     * the server.\n     */\n    public lastAcknowledgedBatchId: number,\n    /**\n     * A stream token that was previously sent by the server.\n     *\n     * See StreamingWriteRequest in datastore.proto for more details about\n     * usage.\n     *\n     * After sending this token, earlier tokens may not be used anymore so\n     * only a single stream token is retained.\n     */\n    public lastStreamToken: string\n  ) {}\n}\n\n/** keys in the 'mutations' object store are [userId, batchId] pairs. */\nexport type DbMutationBatchKey = [string, BatchId];\n\n/**\n * An object to be stored in the 'mutations' store in IndexedDb.\n *\n * Represents a batch of user-level mutations intended to be sent to the server\n * in a single write. Each user-level batch gets a separate DbMutationBatch\n * with a new batchId.\n */\nexport class DbMutationBatch {\n  /** Name of the IndexedDb object store.  */\n  static store = 'mutations';\n\n  /** Keys are automatically assigned via the userId, batchId properties. */\n  static keyPath = ['userId', 'batchId'];\n\n  constructor(\n    /**\n     * The normalized user ID to which this batch belongs.\n     */\n    public userId: string,\n    /**\n     * An identifier for this batch, allocated by the mutation queue in a\n     * monotonically increasing manner.\n     */\n    public batchId: BatchId,\n    /**\n     * The local write time of the batch, stored as milliseconds since the\n     * epoch.\n     */\n    public localWriteTimeMs: number,\n    /**\n     * A list of mutations to apply. All mutations will be applied atomically.\n     *\n     * Mutations are serialized via JsonProtoSerializer.toMutation().\n     */\n    public mutations: api.Write[]\n  ) {}\n}\n\n/**\n * The key for a db document mutation, which is made up of a userID, path, and\n * batchId. Note that the path must be serialized into a form that indexedDB can\n * sort.\n */\nexport type DbDocumentMutationKey = [string, EncodedResourcePath, BatchId];\n\nfunction createMutationQueue(db: IDBDatabase): void {\n  db.createObjectStore(DbMutationQueue.store, {\n    keyPath: DbMutationQueue.keyPath\n  });\n\n  db.createObjectStore(DbMutationBatch.store, {\n    keyPath: DbMutationBatch.keyPath as KeyPath\n  });\n\n  db.createObjectStore(DbDocumentMutation.store);\n}\n\n/**\n * An object to be stored in the 'documentMutations' store in IndexedDb.\n *\n * A manually maintained index of all the mutation batches that affect a given\n * document key. The rows in this table are references based on the contents of\n * DbMutationBatch.mutations.\n */\nexport class DbDocumentMutation {\n  static store = 'documentMutations';\n\n  /**\n   * Creates a [userId] key for use in the DbDocumentMutations index to iterate\n   * over all of a user's document mutations.\n   */\n  static prefixForUser(userId: string): [string] {\n    return [userId];\n  }\n\n  /**\n   * Creates a [userId, encodedPath] key for use in the DbDocumentMutations\n   * index to iterate over all at document mutations for a given path or lower.\n   */\n  static prefixForPath(\n    userId: string,\n    path: ResourcePath\n  ): [string, EncodedResourcePath] {\n    return [userId, encode(path)];\n  }\n\n  /**\n   * Creates a full index key of [userId, encodedPath, batchId] for inserting\n   * and deleting into the DbDocumentMutations index.\n   */\n  static key(\n    userId: string,\n    path: ResourcePath,\n    batchId: BatchId\n  ): DbDocumentMutationKey {\n    return [userId, encode(path), batchId];\n  }\n\n  /**\n   * Because we store all the useful information for this store in the key,\n   * there is no useful information to store as the value. The raw (unencoded)\n   * path cannot be stored because IndexedDb doesn't store prototype\n   * information.\n   */\n  static PLACEHOLDER = new DbDocumentMutation();\n\n  private constructor() {}\n}\n\n/**\n * A key in the 'remoteDocuments' object store is a string array containing the\n * segments that make up the path.\n */\nexport type DbRemoteDocumentKey = string[];\n\nfunction createRemoteDocumentCache(db: IDBDatabase): void {\n  db.createObjectStore(DbRemoteDocument.store);\n}\n\n/**\n * Represents the known absence of a document at a particular version.\n * Stored in IndexedDb as part of a DbRemoteDocument object.\n */\nexport class DbNoDocument {\n  constructor(public path: string[], public readTime: DbTimestamp) {}\n}\n\n/**\n * An object to be stored in the 'remoteDocuments' store in IndexedDb. It\n * represents either a cached document (if it exists) or a cached \"no-document\"\n * (if it is known to not exist).\n *\n * Note: This is the persisted equivalent of a MaybeDocument and could perhaps\n * be made more general if necessary.\n */\nexport class DbRemoteDocument {\n  static store = 'remoteDocuments';\n\n  constructor(\n    /**\n     * Set to an instance of a DbNoDocument if it is known that no document\n     * exists.\n     */\n    public noDocument: DbNoDocument | null,\n    /**\n     * Set to an instance of a Document if there's a cached version of the\n     * document.\n     */\n    public document: api.Document | null\n  ) {}\n}\n\n/**\n * A key in the 'targets' object store is a targetId of the query.\n */\nexport type DbTargetKey = TargetId;\n\n/**\n * The persisted type for a query nested with in the 'targets' store in\n * IndexedDb. We use the proto definitions for these two kinds of queries in\n * order to avoid writing extra serialization logic.\n */\nexport type DbQuery = api.QueryTarget | api.DocumentsTarget;\n\n/**\n * An object to be stored in the 'targets' store in IndexedDb.\n *\n * This is based on and should be kept in sync with the proto used in the iOS\n * client.\n *\n * Each query the client listens to against the server is tracked on disk so\n * that the query can be efficiently resumed on restart.\n */\nexport class DbTarget {\n  static store = 'targets';\n\n  /** Keys are automatically assigned via the targetId property. */\n  static keyPath = 'targetId';\n\n  /** The name of the queryTargets index. */\n  static queryTargetsIndexName = 'queryTargetsIndex';\n\n  /**\n   * The index of all canonicalIds to the targets that they match. This is not\n   * a unique mapping because canonicalId does not promise a unique name for all\n   * possible queries, so we append the targetId to make the mapping unique.\n   */\n  static queryTargetsKeyPath = ['canonicalId', 'targetId'];\n\n  constructor(\n    /**\n     * An auto-generated sequential numeric identifier for the query.\n     *\n     * Queries are stored using their canonicalId as the key, but these\n     * canonicalIds can be quite long so we additionally assign a unique\n     * queryId which can be used by referenced data structures (e.g.\n     * indexes) to minimize the on-disk cost.\n     */\n    public targetId: TargetId,\n    /**\n     * The canonical string representing this query. This is not unique.\n     */\n    public canonicalId: string,\n    /**\n     * The last readTime received from the Watch Service for this query.\n     *\n     * This is the same value as TargetChange.read_time in the protos.\n     */\n    public readTime: DbTimestamp,\n    /**\n     * An opaque, server-assigned token that allows watching a query to be\n     * resumed after disconnecting without retransmitting all the data\n     * that matches the query. The resume token essentially identifies a\n     * point in time from which the server should resume sending results.\n     *\n     * This is related to the snapshotVersion in that the resumeToken\n     * effectively also encodes that value, but the resumeToken is opaque\n     * and sometimes encodes additional information.\n     *\n     * A consequence of this is that the resumeToken should be used when\n     * asking the server to reason about where this client is in the watch\n     * stream, but the client should use the snapshotVersion for its own\n     * purposes.\n     *\n     * This is the same value as TargetChange.resume_token in the protos.\n     */\n    public resumeToken: string,\n    /**\n     * A sequence number representing the last time this query was\n     * listened to, used for garbage collection purposes.\n     *\n     * Conventionally this would be a timestamp value, but device-local\n     * clocks are unreliable and they must be able to create new listens\n     * even while disconnected. Instead this should be a monotonically\n     * increasing number that's incremented on each listen call.\n     *\n     * This is different from the queryId since the queryId is an\n     * immutable identifier assigned to the Query on first use while\n     * lastListenSequenceNumber is updated every time the query is\n     * listened to.\n     */\n    public lastListenSequenceNumber: number,\n    /**\n     * The query for this target.\n     *\n     * Because canonical ids are not unique we must store the actual query. We\n     * use the proto to have an object we can persist without having to\n     * duplicate translation logic to and from a `Query` object.\n     */\n    public query: DbQuery\n  ) {}\n}\n\n/**\n * The key for a DbTargetDocument, containing a targetId and an encoded resource\n * path.\n */\nexport type DbTargetDocumentKey = [TargetId, EncodedResourcePath];\n\n/**\n * An object representing an association between a target and a document.\n * Stored in the targetDocument object store to store the documents tracked by a\n * particular target.\n */\nexport class DbTargetDocument {\n  /** Name of the IndexedDb object store.  */\n  static store = 'targetDocuments';\n\n  /** Keys are automatically assigned via the targetId, path properties. */\n  static keyPath = ['targetId', 'path'];\n\n  /** The index name for the reverse index. */\n  static documentTargetsIndex = 'documentTargetsIndex';\n\n  /** We also need to create the reverse index for these properties. */\n  static documentTargetsKeyPath = ['path', 'targetId'];\n\n  constructor(\n    /**\n     * The targetId identifying a target.\n     */\n    public targetId: TargetId,\n    /**\n     * The path to the document, as encoded in the key.\n     */\n    public path: EncodedResourcePath\n  ) {}\n}\n\n/**\n * The type to represent the single allowed key for the DbTargetGlobal store.\n */\nexport type DbTargetGlobalKey = typeof DbTargetGlobal.key;\n\n/**\n * A record of global state tracked across all Targets, tracked separately\n * to avoid the need for extra indexes.\n *\n * This should be kept in-sync with the proto used in the iOS client.\n */\nexport class DbTargetGlobal {\n  /**\n   * The key string used for the single object that exists in the\n   * DbTargetGlobal store.\n   */\n  static key = 'targetGlobalKey';\n  static store = 'targetGlobal';\n\n  constructor(\n    /**\n     * The highest numbered target id across all targets.\n     *\n     * See DbTarget.targetId.\n     */\n    public highestTargetId: TargetId,\n    /**\n     * The highest numbered lastListenSequenceNumber across all targets.\n     *\n     * See DbTarget.lastListenSequenceNumber.\n     */\n    public highestListenSequenceNumber: number,\n    /**\n     * A global snapshot version representing the last consistent snapshot we\n     * received from the backend. This is monotonically increasing and any\n     * snapshots received from the backend prior to this version (e.g. for\n     * targets resumed with a resumeToken) should be suppressed (buffered)\n     * until the backend has caught up to this snapshot version again. This\n     * prevents our cache from ever going backwards in time.\n     */\n    public lastRemoteSnapshotVersion: DbTimestamp,\n    /**\n     * The number of targets persisted.\n     */\n    public targetCount: number\n  ) {}\n}\n\nfunction createQueryCache(db: IDBDatabase): void {\n  const targetDocumentsStore = db.createObjectStore(DbTargetDocument.store, {\n    keyPath: DbTargetDocument.keyPath as KeyPath\n  });\n  targetDocumentsStore.createIndex(\n    DbTargetDocument.documentTargetsIndex,\n    DbTargetDocument.documentTargetsKeyPath,\n    { unique: true }\n  );\n\n  const targetStore = db.createObjectStore(DbTarget.store, {\n    keyPath: DbTarget.keyPath\n  });\n\n  // NOTE: This is unique only because the TargetId is the suffix.\n  targetStore.createIndex(\n    DbTarget.queryTargetsIndexName,\n    DbTarget.queryTargetsKeyPath,\n    { unique: true }\n  );\n  db.createObjectStore(DbTargetGlobal.store);\n}\n\n/**\n * Counts the number of targets persisted and adds that value to the target\n * global singleton.\n */\nfunction saveTargetCount(\n  txn: SimpleDbTransaction,\n  metadata: DbTargetGlobal\n): PersistencePromise<void> {\n  const globalStore = txn.store<DbTargetGlobalKey, DbTargetGlobal>(\n    DbTargetGlobal.store\n  );\n  const targetStore = txn.store<DbTargetKey, DbTarget>(DbTarget.store);\n  return targetStore.count().next(count => {\n    metadata.targetCount = count;\n    return globalStore.put(DbTargetGlobal.key, metadata);\n  });\n}\n\n/**\n * Ensures that the target global singleton row exists by adding it if it's\n * missing.\n *\n * @param {IDBTransaction} txn The version upgrade transaction for indexeddb\n */\nfunction ensureTargetGlobalExists(\n  txn: SimpleDbTransaction\n): PersistencePromise<DbTargetGlobal> {\n  const globalStore = txn.store<DbTargetGlobalKey, DbTargetGlobal>(\n    DbTargetGlobal.store\n  );\n  return globalStore.get(DbTargetGlobal.key).next(metadata => {\n    if (metadata != null) {\n      return PersistencePromise.resolve(metadata);\n    } else {\n      metadata = new DbTargetGlobal(\n        /*highestTargetId=*/ 0,\n        /*lastListenSequenceNumber=*/ 0,\n        SnapshotVersion.MIN.toTimestamp(),\n        /*targetCount=*/ 0\n      );\n      return globalStore.put(DbTargetGlobal.key, metadata).next(() => metadata);\n    }\n  });\n}\n\n/**\n * The list of all default IndexedDB stores used throughout the SDK. This is\n * used when creating transactions so that access across all stores is done\n * atomically.\n */\nexport const ALL_STORES = [\n  DbMutationQueue.store,\n  DbMutationBatch.store,\n  DbDocumentMutation.store,\n  DbRemoteDocument.store,\n  DbTarget.store,\n  DbOwner.store,\n  DbTargetGlobal.store,\n  DbTargetDocument.store\n];\n"]},"metadata":{},"sourceType":"module"}